{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFT count rarity\n",
    "\n",
    "This script is used to count absolute rarity of you images based on traits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "from IPython.display import display \n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each image is made up a series of traits\n",
    "# The weightings for each trait drive the rarity and add up to 100%\n",
    "AllTraits = [\n",
    "    {\n",
    "        \"name\": \"Hair\",\n",
    "        \"traits\":  [\"hair1\", \"hair2\", \"hair3\", \"hair4\"],\n",
    "        \"weights\": [30, 20, 10, 40],\n",
    "        \"folder\": \"hair\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Accessory\",\n",
    "        \"traits\":  [\"accessory1\", \"accessory2\", \"accessory3\", \"accessory4\"] ,\n",
    "        \"weights\": [25, 25, 25, 25],\n",
    "        \"folder\": \"accessory\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Face\",\n",
    "        \"traits\":  [\"face1\", \"face2\", \"face3\", \"face4\"],\n",
    "        \"weights\": [25, 25, 25, 25],\n",
    "        \"folder\": \"face\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Body\",\n",
    "        \"traits\":  [\"Duck\"],\n",
    "        \"weights\": [100],\n",
    "        \"files\": [\"Duck\"],\n",
    "        \"folder\": \"body\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Background\",\n",
    "        \"traits\":  [\"Green\",\"Yellow\",\"Blue\",\"White\"],\n",
    "        \"weights\": [30, 10, 20, 40],\n",
    "        \"folder\": \"background\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hair: t: 4, w: 4\n",
      "Accessory: t: 4, w: 4\n",
      "Face: t: 4, w: 4\n",
      "Body: t: 1, w: 1\n",
      "Background: t: 4, w: 4\n",
      "=====\n",
      "Hair: \n",
      "{'hair1': 5, 'hair2': 8, 'hair3': 1, 'hair4': 18}\n",
      "Accessory: \n",
      "{'accessory1': 5, 'accessory2': 12, 'accessory3': 7, 'accessory4': 8}\n",
      "Face: \n",
      "{'face1': 7, 'face2': 10, 'face3': 6, 'face4': 9}\n",
      "Body: \n",
      "{'Duck': 32}\n",
      "Background: \n",
      "{'Green': 11, 'Yellow': 2, 'Blue': 6, 'White': 13}\n"
     ]
    }
   ],
   "source": [
    "## Load traits\n",
    "\n",
    "TOTAL_IMAGES = 32 # Number of random unique images we want to generate\n",
    "\n",
    "all_images = [] \n",
    "\n",
    "# do check weights\n",
    "for trait in AllTraits:\n",
    "    print(trait[\"name\"] +\": t: \"+ str(len(trait[\"traits\"]))+ \", w: \" + str(len(trait[\"weights\"])))\n",
    "\n",
    "#### Generate Metadata for all Traits \n",
    "METADATA_FILE_NAME = './metadata/all-traits.json'; \n",
    "    \n",
    "with open(METADATA_FILE_NAME) as json_file:\n",
    "    all_images = json.load(json_file)\n",
    "\n",
    "### Sort traits\n",
    "traits = {}\n",
    "for trait in AllTraits:\n",
    "    traits[trait[\"name\"]]={}\n",
    "    i=0\n",
    "    for tr in trait[\"traits\"]:\n",
    "        traits[trait[\"name\"]][tr] = trait[\"weights\"][i] \n",
    "        i+=1\n",
    "\n",
    "counts = {}\n",
    "\n",
    "for trait in AllTraits:\n",
    "    counts[trait[\"name\"]] = {}\n",
    "    for item in trait[\"traits\"]:\n",
    "        counts[trait[\"name\"]][item] = 0\n",
    "\n",
    "for image in all_images:\n",
    "    for k,c in counts.items():\n",
    "        counts[k][image[k]] += 1\n",
    "\n",
    "print(\"=====\")\n",
    "\n",
    "for k in counts:\n",
    "    print(k + \": \")\n",
    "    print(counts[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count rarity\n",
    "i = 0\n",
    "for item in all_images:\n",
    "    rarity = 1\n",
    "    j=0\n",
    "    for k, v in item.items():\n",
    "        j+=1\n",
    "        if(k!='tokenId'):\n",
    "            #print(traits[k][v])\n",
    "            rarity = rarity * traits[k][v]\n",
    "        #print(rarity)\n",
    "    item[\"rarity\"] = rarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 = 25000000\n",
      "10 = 25000000\n",
      "15 = 25000000\n",
      "17 = 25000000\n",
      "25 = 25000000\n",
      "6 = 37500000\n",
      "8 = 37500000\n",
      "18 = 37500000\n",
      "26 = 37500000\n",
      "13 = 50000000\n",
      "14 = 50000000\n",
      "16 = 50000000\n",
      "21 = 50000000\n",
      "22 = 50000000\n",
      "28 = 50000000\n",
      "0 = 56250000\n",
      "3 = 75000000\n",
      "4 = 75000000\n",
      "9 = 75000000\n",
      "12 = 75000000\n",
      "19 = 75000000\n",
      "20 = 75000000\n",
      "23 = 75000000\n",
      "24 = 75000000\n",
      "29 = 75000000\n",
      "31 = 75000000\n",
      "1 = 100000000\n",
      "2 = 100000000\n",
      "5 = 100000000\n",
      "11 = 100000000\n",
      "27 = 100000000\n",
      "30 = 100000000\n"
     ]
    }
   ],
   "source": [
    "# Sort by rarity\n",
    "\n",
    "rarited = sorted(all_images, key=lambda d: d['rarity']) \n",
    "\n",
    "raritysumm = 0\n",
    "\n",
    "tosave = []\n",
    "i = 0\n",
    "for item in rarited:\n",
    "    raritysumm += item[\"rarity\"] \n",
    "    tosave.append({\"tokenId\":item[\"tokenId\"],\"rarity\":item[\"rarity\"]})\n",
    "    #out = str(item[\"tokenId\"])+ \" = \" + str(item[\"rarity\"] / 1000000000)\n",
    "    out = str(item[\"tokenId\"])+ \" = \" + str(item[\"rarity\"])\n",
    "    print(out)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "RARITY_FILE_NAME = './rarity.json'; \n",
    "with open(RARITY_FILE_NAME, 'w') as outfile:\n",
    "    json.dump(tosave, outfile, indent=4)\n",
    "\n",
    "RARITY_FILE_NAME_TXT = './rarity.txt'; \n",
    "with open(RARITY_FILE_NAME_TXT, 'w') as outfile:\n",
    "    for line in tosave:\n",
    "        out = str(line[\"tokenId\"])+ \" = \" + str(line[\"rarity\"])\n",
    "        outfile.write(out)\n",
    "        outfile.write('\\n')\n",
    "\n",
    "with open('./rarity_.txt', 'w') as outfile:\n",
    "    i = 0\n",
    "    for line in tosave:\n",
    "        out = str(i)+ \") â„–\" +str(line[\"tokenId\"])\n",
    "        outfile.write(out)\n",
    "        outfile.write('\\n')\n",
    "        i+=1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c87b3114766150af71784ead996335dbe6b62987c353b6dd80c644a925234bfe"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
